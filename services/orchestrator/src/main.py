import json
import os
from datetime import date, datetime, timedelta, timezone

from openai import OpenAI

from services.copywriter.article_selector.src.main import choose_articles_for_structure
from services.copywriter.structure_builder.src.main import propose_structure
from services.copywriter.summary_generator.src.main import generate_summary_structured
from services.decision_engine.src.main import decide_publications
from services.nlp.src.main import analyze_articles
from services.orchestrator.src.utils import markdown_to_html
from services.publisher.src.main import publish_newsletter_post
from services.scraper.fulltext.src.fulltext_scraper import scrape_full_text
from services.scraper.src.main import scrape_articles
from services.shared.utils.dates import filter_articles_by_date_range


async def run_pipeline():
    print("ğŸ” Scrapeando artÃ­culos...")
    articles = await scrape_articles()

    if not articles:
        print("âš ï¸ No se encontraron artÃ­culos para procesar.")
        return

    print(f"ğŸ“° {len(articles)} artÃ­culos encontrados")
    for article in articles:
        print(
            f"- {article.title[:20]} ({article.published_at.strftime('%Y-%m-%d')}) - Resumen: {article.summary[:30]} - URL: {article.url}"
        )

    # Filtro: Ãºltimos 7 dÃ­as
    today_utc = datetime.now(timezone.utc)
    last_week = today_utc - timedelta(days=7)
    recent_articles = filter_articles_by_date_range(
        articles, start_date=last_week, end_date=today_utc
    )

    print(
        f"ğŸ“š {len(recent_articles)} artÃ­culos encontrados en los Ãºltimos 7 dÃ­as. Procesando NLP..."
    )
    analyzed_articles = analyze_articles(recent_articles)

    print("ğŸ§  Evaluando publicaciones...")
    decisions = decide_publications(analyzed_articles)
    to_publish = [d for d in decisions if d.should_publish]

    if not to_publish:
        print("âš ï¸ No se encontraron artÃ­culos relevantes para publicar.")
        return

    # Preparamos lista de diccionarios con campos bÃ¡sicos para proponer estructura
    print(
        f"ğŸ“‘ {len(to_publish)} artÃ­culos marcados para publicar. Generando estructura con LLM..."
    )
    candidates = []
    for d in to_publish:
        candidates.append(
            {
                "title": d.article.title,
                "summary": d.article.summary,
                "url": d.article.url,
                "date": d.article.published_at.strftime("%Y-%m-%d"),
            }
        )

    # 1) Proponer estructura
    structure_template = propose_structure(candidates)
    structure_dict = structure_template.model_dump()

    print("âœï¸ Estructura propuesta:")
    for sec in structure_dict["structure"]:
        print(f"- {sec['section_title']} ({sec['description']})")

    # 2) Seleccionar artÃ­culos definitivos segÃºn la estructura
    print("ğŸ“‹ Seleccionando artÃ­culos finales para cada secciÃ³n...")
    selection_result = choose_articles_for_structure(structure_dict, candidates)
    final_articles = selection_result.final_articles

    # VerificaciÃ³n de coincidencia exacta de 'section'
    secciones_definidas = {sec["section_title"] for sec in structure_dict["structure"]}
    for art in final_articles:
        if art.section not in secciones_definidas:
            print(
                f'[NEWSLETTER][WARNING] El artÃ­culo "{art.title}" tiene section "{art.section}" '
                f"pero no coincide con ningÃºn section_title: {secciones_definidas}"
            )

    # 3) Para cada artÃ­culo seleccionado: extraer fulltext y generar resumen estructurado
    print("ğŸ”„ Generando resÃºmenes detallados para cada artÃ­culo seleccionado...")
    articles_for_json = []
    from services.copywriter.summary_generator.src.models import (
        ArticleSummaryStructured,
    )

    for art in final_articles:
        url = art.url
        title = art.title
        section = art.section

        full_text = await scrape_full_text(url)
        if full_text:
            summary_struct = generate_summary_structured(full_text, section)
            if summary_struct is None:
                summary_struct = ArticleSummaryStructured(
                    key_points=[
                        f'No se pudo generar resumen detallado para "{title}".'
                    ],
                    pull_quote="",
                    narrative_summary=f"Resumen breve original: {title}",
                    implications="",
                    resources=[],
                )
        else:
            summary_struct = ArticleSummaryStructured(
                key_points=[f'No se pudo obtener el texto completo para "{title}".'],
                pull_quote="",
                narrative_summary=f"Resumen breve original: {title}",
                implications="",
                resources=[],
            )
            print(f"âš ï¸ No se pudo obtener el texto completo para: {title} (URL: {url})")

        raw = summary_struct.model_dump()
        if raw.get("resources"):
            for recurso in raw["resources"]:
                recurso["url"] = str(recurso["url"])

        articles_for_json.append(
            {"title": title, "url": url, "section": section, "summary_struct": raw}
        )

    # 4) Llamada final al LLM para generar el boletÃ­n completo en Markdown
    print("ğŸ¤– Construyendo prompt para generar newsletter completo...")
    prompt_path = os.path.join(
        os.path.dirname(__file__),
        "../../copywriter/src/prompts/generate_newsletter_prompt.txt",
    )

    with open(prompt_path, "r", encoding="utf-8") as f:
        prompt_template = f.read()

    structure_json_str = json.dumps(structure_dict, ensure_ascii=False)
    articles_json_str = json.dumps(articles_for_json, ensure_ascii=False)

    print("[NEWSLETTER] â†’ Generando prompt completo para el boletÃ­n")
    print(
        "STRUCTURE_JSON:",
        structure_json_str[:200] + ("..." if len(structure_json_str) > 200 else ""),
    )
    print(
        "ARTICLES_JSON:",
        articles_json_str[:200] + ("..." if len(articles_json_str) > 200 else ""),
    )

    prompt = prompt_template.replace("{structure_json}", structure_json_str).replace(
        "{articles_json}", articles_json_str
    )

    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    try:
        response = client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=[
                {
                    "role": "system",
                    "content": "Eres un redactor mÃ©dico experto en oncologÃ­a.",
                },
                {"role": "user", "content": prompt},
            ],
            temperature=0.1,
            max_tokens=6000,
        )
        newsletter_md = response.choices[0].message.content.strip()
    except Exception as e:
        print(f"[Error] En llamada a OpenAI: {e}")
        return

    # 5) Convertir Markdown a HTML y publicar
    print("ğŸ”„ Convirtiendo Markdown a HTML...")
    print(newsletter_md)
    if newsletter_md.startswith("```markdown"):
        newsletter_md = (
            newsletter_md.replace("```markdown", "").replace("```", "").strip()
        )
    elif newsletter_md.startswith("```"):
        newsletter_md = newsletter_md.replace("```", "").strip()
    html_body = markdown_to_html(newsletter_md)

    post_title = (
        f"BoletÃ­n semanal de cÃ¡ncer de seno â€” {date.today().strftime('%Y-%m-%d')}"
    )
    print(f"ğŸš€ Publicando newsletter '{post_title}' en Plataforma...")
    result = publish_newsletter_post(title=post_title, content=html_body)

    status = (
        "âœ… Publicado con Ã©xito" if result.published else f"âŒ FallÃ³: {result.message}"
    )
    print(f"ğŸ“¢ Resultado: {status}")
